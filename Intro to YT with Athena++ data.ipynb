{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using YT with Athena++ Data\n",
    "\n",
    "## Loading Data\n",
    "\n",
    "While the initial data importing applies to Athena++ HDF5 data in particular, the plotting files in this repo are useful for other data sets imported with YT. \n",
    "\n",
    "First, we load in some libraries. The matplotlib libraries are brought in for comparison to YT plots. Glob is for loading in a particular folder of files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib plotting modules\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "\n",
    "##numpy and file editing\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Problem/physics modules\n",
    "import units_Parker\n",
    "\n",
    "##YT modules\n",
    "import yt\n",
    "from yt.visualization.api import Streamlines\n",
    "import yt.units as u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load in the data from a simulation. A common file path/directory setup for athena++ runs is shown below. Path is the location of data for a bunch of problems. Prob is related to the specific problem generator used and run is a folder within that problem folder. The run folder should have all the data files. The directories should look like so:\n",
    "\n",
    "- `path`\n",
    "    - `prob`\n",
    "        - `run`\n",
    "          - `outfileNom.out1.00000.athdf`\n",
    "          - `outfileNom.out1.00001.athdf`\n",
    "          - .......\n",
    "          \n",
    "The code block below creates a list `dsLst` of datasets, ordered by time step.\n",
    "\n",
    "Note that to get the data set to print out or use non-code units, you need to specify `in_base('cgs')` with some unit system. The units are in the dataset object as a result of the `units_override` parameter in `load`. The code below outputs the available data fields in the dataset along with the density variable at the zeroth time step of the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available fields from the HDF5 file: \n",
      "('athena_pp', 'Bcc1')\n",
      "('athena_pp', 'Bcc2')\n",
      "('athena_pp', 'Bcc3')\n",
      "('athena_pp', 'press')\n",
      "('athena_pp', 'rho')\n",
      "('athena_pp', 'vel1')\n",
      "('athena_pp', 'vel2')\n",
      "('athena_pp', 'vel3')\n",
      "\n",
      "The density variable in cgs units: \n",
      "[1.e-24 1.e-24 1.e-24 ... 1.e-24 1.e-24 1.e-24] g/cm**3\n"
     ]
    }
   ],
   "source": [
    "path   = './'\n",
    "prob   = 'Parker' ##The name of the athena problem generator is ParkerInst\n",
    "outfileNom = \"parker\" \n",
    "run = \"testAW\" ##This is an Alfven wave test in a uniform background medium\n",
    "suffix = 'athdf'\n",
    "out = 1\n",
    "\n",
    "myUnits = units_Parker.Parker()\n",
    "\n",
    "units= {\"length_unit\":(myUnits.ls.value,str(myUnits.ls.unit)),\n",
    "                  \"time_unit\":(myUnits.ts.value,str(myUnits.ts.unit)),\n",
    "                  \"mass_unit\":(myUnits.ms.value,str(myUnits.ms.unit))}\n",
    "\n",
    "fileName = (\"%s%s/%s/%s.out%1i*.%s\") % (path, prob, run,\n",
    "                                            outfileNom,out,suffix)\n",
    "\n",
    "fileLst = glob.glob(fileName)\n",
    "fileLst = np.sort(fileLst)\n",
    "\n",
    "dsLst = []\n",
    "for file in fileLst:\n",
    "    ds = yt.load(file,units_override=units)\n",
    "    dsLst.append(ds)\n",
    "    \n",
    "print(\"Available fields from the HDF5 file: \")\n",
    "for entry in dsLst[0].field_list:\n",
    "    print(entry)\n",
    "print()\n",
    "print(\"The density variable in cgs units: \")\n",
    "ad = dsLst[0].all_data()\n",
    "print(ad['athena_pp','rho'].in_base('cgs'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are all the data fields included in the HDF5 file. \n",
    "\n",
    "There are also derived fields and index fields. Derived fields are other physical variables calculated based on the data in the HDF5 file. Index fields come from the HDF5 file and correspond to the grid/mesh that the code was run on. \n",
    "\n",
    "I.e. `('index','x')` will give you the coordinates along the $\\hat{x}$ axis in the simulation. Let's look at this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The x coordinates are: \n",
      "[3.16482352e-01 3.16482352e-01 3.16482352e-01 ... 3.23761447e+02\n",
      " 3.23761447e+02 3.23761447e+02] pc\n",
      "\n",
      "The volume of each cell is: \n",
      "[519.35992295 519.35992295 519.35992295 ... 519.35992295 519.35992295\n",
      " 519.35992295] pc**3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ad = dsLst[0].all_data()\n",
    "print(\"The x coordinates are: \")\n",
    "print(ad['index','x'].in_units('pc'))\n",
    "print()\n",
    "print(\"The volume of each cell is: \")\n",
    "print(ad['index','cell_volume'].in_units('pc**3'))\n",
    "print()\n",
    "\n",
    "#To see every field in the dataset object, uncomment the code below:\n",
    "#for entry in dsLst[0].derived_field_list:\n",
    "#    print(entry)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
